const JOB_LEXER string = "Lexer";

struct Lexer {
	source byte[]
	index int
	line int
}

// Returns the character that is next
// in line, is useful when you have a
// duo of characters to create a token
fun (l Lexer^) peekChar() byte {
	if l.index >= l.source.len-1 {
		return 0;
	}

	return [l.index+1]l.source;
}

fun (l Lexer^) lex() Token[] {
	tokens Token[];
	token Token;

	for ; l.index < l.source.len; ++l.index {
		// Automatically sets it to ILLEGAL
		token = new Token();

		switch [l.index]l.source {

		// Unnecessary to compute
		case ' ':
			continue;
		case '\t':
			continue;
		case '\n':
			++l.line;
			continue;
		case '\r':
			continue;

		// Actual symbols
		case ';':
			token = new Token(";", T_SEMICOLON, l.line);

		case '.':
			token = new Token(".", T_ACCESS, l.line);

		case ':':
			token = new Token(":", T_COLON, l.line);

		case '~':
			token = new Token("~", T_XOR, l.line);

		case '`':
			token = new Token("`", T_REF, l.line);

		case '^':
			token = new Token("^", T_DEREF, l.line);

		case '{':
			token = new Token("{", T_L_SQUIRLY, l.line);

		case '}':
			token = new Token("}", T_R_SQUIRLY, l.line);

		case '[':
			token = new Token("[", T_L_BLOCK, l.line);

		case ']':
			token = new Token("]", T_R_BLOCK, l.line);

		case '(':
			token = new Token("(", T_L_PAREN, l.line);

		case ')':
			token = new Token(")", T_R_PAREN, l.line);

		case ',':
			token = new Token(",", T_SEP, l.line);

		case '%':
			token = new Token("%", T_MOD, l.line);

		case '*':
			token = new Token("*", T_MUL, l.line);

		// Doubles
		case '|':
			token = new Token("|", T_OR, l.line);
			if call l.peekChar() == '|' {
				token = new Token("||", T_OROR, l.line);
				++l.index;
			}

		case '&':
			token = new Token("&", T_AND, l.line);
			if call l.peekChar() == '&' {
				token = new Token("&&", T_ANDAND, l.line);
				++l.index;
			}

		case '=':
			token = new Token("=", T_ASSIGN, l.line);
			if call l.peekChar() == '=' {
				token = new Token("==", T_EQ, l.line);
				++l.index;
			}

		case '!':
			token = new Token("!", T_NOT, l.line);
			if call l.peekChar() == '=' {
				token = new Token("!=", T_NEQ, l.line);
				++l.index;
			}

		case '+':
			token = new Token("+", T_ADD, l.line);
			if call l.peekChar() == '+' {
				token = new Token("++", T_INC, l.line);
				++l.index;
			}

		case '-':
			token = new Token("-", T_SUB, l.line);
			if call l.peekChar() == '-' {
				token = new Token("--", T_DINC, l.line);
				++l.index;
			}

		// Complicated doubles
		case '<':
			token = new Token("<", T_LT, l.line);
			if call l.peekChar() == '=' {
				token = new Token("<=", T_LTEQ, l.line);
				++l.index;
			} elif call l.peekChar() == '<' {
				token = new Token("<<", T_L_SHIFT, l.line);
				++l.index;
			}

		case '>':
			token = new Token(">", T_GT, l.line);
			if call l.peekChar() == '=' {
				token = new Token(">=", T_GTEQ, l.line);
				++l.index;
			} elif call l.peekChar() == '>' {
				token = new Token(">>", T_R_SHIFT, l.line);
				++l.index;
			}

		case '/':
			token = new Token("/", T_DIV, l.line);

			// single-line comment
			if call l.peekChar() == '/' {
				while call l.peekChar() != '\n' && call l.peekChar() != 0 {

					// Make sure line numbers make sense
					if call l.peekChar() == '\n' {
						++l.line;
					}

					++l.index;
				}
				continue;
			}

			// multi-line comment
			if call l.peekChar() == '*' {
				while call l.peekChar() != 0 {

					// Make sure line numbers make sense
					if call l.peekChar() == '\n' {
						++l.line;
					}
					if call l.peekChar() == '/' && [l.index]l.source == '*' {
						++l.index;
						break;
					}
					++l.index;
				}
				continue;
			}

		case '\'': // Characters
			token = new Token("'", T_CHAR, l.line);

			if call l.peekChar() == '\\' {
				l.index = l.index + 3;
				if l.index >= l.source.len {
					call l.throwError("character", l.line, "more source", "end of source");
				}

				if [l.index]l.source != '\'' {
					call l.throwError("character", l.line, "' (single quote)", call tostring([l.index]l.source));
				}
				token.data = token.data + call tostring([l.index-2]l.source) + call tostring([l.index-1]l.source) + call tostring([l.index]l.source);
			} else {
				l.index = l.index + 2;
				if l.index >= l.source.len {
					call l.throwError("character", l.line, "more source", "end of source");
				}

				if [l.index]l.source != '\'' {
					call l.throwError("character", l.line, "' (single quote)", call tostring([l.index]l.source));
				}
				token.data = token.data + call tostring([l.index-1]l.source) + call tostring([l.index]l.source);
			}

		case '"': // Strings
			token = new Token("\"", T_STRING, l.line);

			escaped bool = false;
			while !(call l.peekChar() == '"' && !escaped) && call l.peekChar() != 0 {
				++l.index;
				token.data = token.data + call tostring([l.index]l.source);
				if [l.index]l.source == '\\' {
					escaped = true;
				} else {
					escaped = false;
				}
			}

			if call l.peekChar() != '"' {
				call l.throwError("string", l.line, "\" (end of string)", "end of source");
			}

			++l.index;
			token.data = token.data + call tostring([l.index]l.source);
		}

		// Numbers
		if [l.index]l.source-'0' <= 9 {
			// We don't know what type of number
			// yet, but we'll figure it out later.
			// At least we know it can only be
			// either integer, float, or illegal
			token = new Token(call tostring([l.index]l.source), T_ILLEGAL, l.line);

			isFloat bool = false;

			while (call l.peekChar()-'0' <= 9 || call l.peekChar() == '.') && call l.peekChar() != 0 {
				++l.index;
				token.data = token.data + call tostring([l.index]l.source);

				if [l.index]l.source == '.' {
					isFloat = true;
				}
			}

			if isFloat {
				if [token.data.len-1]token.data == '.' {
					call panic("Floats cannot end with '.'");
				}
				token.kind = T_FLOAT;
			} else {
				token.kind = T_INT;
			}

			// Keywords
			// Other words
		} elif [l.index]l.source-'a' < 26 || [l.index]l.source-'A' < 26 {
			// Don't know specific type yet
			token = new Token(call tostring([l.index]l.source), T_ILLEGAL, l.line);

			while (call l.peekChar()-'a' < 26 || call l.peekChar()-'A' < 26 || call l.peekChar() == '_') && call l.peekChar() != 0 {
				++l.index;
				token.data = token.data + call tostring([l.index]l.source);
			}

			// Keywords
			switch token.data {
			case "for":
				token.kind = T_FOR;
			case "range":
				token.kind = T_RANGE;
			case "forever":
				token.kind = T_FOREVER;
			case "while":
				token.kind = T_WHILE;
			case "if":
				token.kind = T_IF;
			case "elif":
				token.kind = T_ELIF;
			case "else":
				token.kind = T_ELSE;
			case "call":
				token.kind = T_CALL;
			case "struct":
				token.kind = T_STRUCT;
			case "fun":
				token.kind = T_FUN;
			case "return":
				token.kind = T_RET;
			case "break":
				token.kind = T_BREAK;
			case "continue":
				token.kind = T_CONT;
			case "enum":
				token.kind = T_ENUM;
			case "nil":
				token.kind = T_NIL;
			case "typedef":
				token.kind = T_TYPEDEF;
			case "new":
				token.kind = T_NEW;
			case "make":
				token.kind = T_MAKE;
			case "map":
				token.kind = T_MAP;
			case "switch":
				token.kind = T_SWITCH;
			case "case":
				token.kind = T_CASE;
			case "default":
				token.kind = T_DEFAULT;
			case "const":
				token.kind = T_CONST;
			case "true":
				token.kind = T_BOOL;
			case "false":
				token.kind = T_BOOL;

				// Types
			case "byte":
				token.kind = T_TYPE;
			case "word":
				token.kind = T_TYPE;
			case "dword":
				token.kind = T_TYPE;
			case "qword":
				token.kind = T_TYPE;
			case "uint8":
				token.kind = T_TYPE;
			case "uint16":
				token.kind = T_TYPE;
			case "uint32":
				token.kind = T_TYPE;
			case "uint64":
				token.kind = T_TYPE;
			case "uint":
				token.kind = T_TYPE;
			case "int8":
				token.kind = T_TYPE;
			case "int16":
				token.kind = T_TYPE;
			case "int32":
				token.kind = T_TYPE;
			case "int64":
				token.kind = T_TYPE;
			case "sint":
				token.kind = T_TYPE;
			case "int":
				token.kind = T_TYPE;
			case "char":
				token.kind = T_TYPE;
			case "string":
				token.kind = T_TYPE;
			case "float32":
				token.kind = T_TYPE;
			case "float64":
				token.kind = T_TYPE;
			case "double":
				token.kind = T_TYPE;
			case "float":
				token.kind = T_TYPE;
			case "bool":
				token.kind = T_TYPE;
			case "any":
				token.kind = T_TYPE;

				// Identifiers
			default:
				// TODO: I think types and identifiers
				// should be considered the same thing

				// HOWEVER, the programmer is allowed
				// to create new types, and the 2 cases
				// that this occurs is in struct and
				// typdefs. It could also be a type if
				// the previous token is new, but the
				// programmer could be lying, so this
				// will be up to semantic analysis. The
				// last case is an identifier after
				// an identifier, which is usually
				// where a type is, so we will also add
				// this case

				// First token in the file (therefore
				// can't be preceeded with the relevant
				// tokens)
				if tokens.len == 0 {
					token.kind = T_IDENTIFIER;
					break;
				}

				// Could possibly be a type
				prevToken Token = [tokens.len-1]tokens;
				if prevToken.kind == T_STRUCT ||
					prevToken.kind == T_TYPEDEF ||
					prevToken.kind == T_NEW ||
					prevToken.kind == T_IDENTIFIER ||
					prevToken.kind == T_MAP {
					token.kind = T_TYPE;
				} else {
					token.kind = T_IDENTIFIER;
				}
			}
		}

		if token.kind == T_ILLEGAL {
			call l.throwError("lexing", l.line, "anything else", "ILLEGAL ("+call tostring([l.index]l.source)+")");
		}

		call tokens.append(token);
	}

	return tokens;
}

fun (l Lexer^) throwError(caller string, line int, expected string, got string) {
	call panic("Error in the " + JOB_LEXER + "!\n" +
		"When the " + JOB_LEXER + " was trying to decipher: " + caller + "\n" +
		"Error found on line " + call tostring(line) + "\n" +
		"Expected: " + expected + "\n" +
		"Got: " + got
	);
}
